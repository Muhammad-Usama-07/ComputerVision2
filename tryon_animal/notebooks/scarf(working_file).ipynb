{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1121a8ef-13f6-4aa1-ae97-b8a5a57dbce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(img, new_width=None, new_height=None):\n",
    "    # Get the current height and width\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # If only width is specified\n",
    "    if new_width is not None and new_height is None:\n",
    "        # Calculate the aspect ratio and new height\n",
    "        aspect_ratio = width / height\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "\n",
    "    # If only height is specified\n",
    "    elif new_height is not None and new_width is None:\n",
    "        # Calculate the aspect ratio and new width\n",
    "        aspect_ratio = height / width\n",
    "        new_width = int(new_height / aspect_ratio)\n",
    "\n",
    "    # If both width and height are specified, ignore aspect ratio\n",
    "    elif new_width is not None and new_height is not None:\n",
    "        pass\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_width, new_height))\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f72ab9ff-fb87-4bb5-86cd-5224403d1d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, landmarks):\n",
    "\n",
    "    radius = 5\n",
    "    # Check if image width is greater than 1000 px.\n",
    "    # To improve visualization.\n",
    "    print('*********** landmarks: ', landmarks)\n",
    "    \n",
    "    if (image.shape[1] > 1000):\n",
    "        radius = 8\n",
    "\n",
    "    for idx, kpt_data in enumerate(landmarks):\n",
    "\n",
    "        # loc_x, loc_y = kpt_data[:2].astype(\"int\").tolist()\n",
    "        loc_x, loc_y = kpt_data[:2]\n",
    "        \n",
    "        color_id = list(COLORS_RGB_MAP[int(kpt_data[-1])].values())[0]\n",
    "\n",
    "        cv2.circle(image,\n",
    "                   (loc_x, loc_y),\n",
    "                   radius,\n",
    "                   color=color_id[::-1],\n",
    "                   thickness=-1,\n",
    "                   lineType=cv2.LINE_AA)\n",
    "         # Draw keypoint number\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 0.5\n",
    "        font_thickness = 1\n",
    "        # text = str(int(kpt_data[-1]))\n",
    "        text = f\"{int(kpt_data[-1])}: ({loc_x}, {loc_y})\"\n",
    "        text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]\n",
    "        text_x = loc_x - text_size[0] // 2\n",
    "        text_y = loc_y - radius - 5\n",
    "        print('************* text:', text)\n",
    "        cv2.putText(image, text, (text_x, text_y), font, font_scale, color=(255, 255, 255), thickness=font_thickness)\n",
    "\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef6690d3-7a9a-43ff-b399-91691b41187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wear_collar(accessories_img,animal_image,  filter_kpts):\n",
    "    ############################### cap working ############################### \n",
    "    # get value of 8 and 2\n",
    "    point_8 = next(sublist for sublist in filter_kpts if sublist[2] == 8)\n",
    "    point_2 = next(sublist for sublist in filter_kpts if sublist[2] == 2)\n",
    "    print('point_8 and point_2', point_8, point_2 )\n",
    "\n",
    "    ### check if point 8 and point 2 exits \n",
    "    if point_8 and point_2:\n",
    "        print('exits+++++++++++++++++')\n",
    "\n",
    "        #### width between 8 and 2\n",
    "        width_8_2 = np.sqrt((point_2[0] - point_8[0])**2 + (point_2[1] - point_8[1])**2)\n",
    "\n",
    "        #### resize image according to width if the 8 and 2 points \n",
    "        resized_accessories_img  = resize_with_aspect_ratio(accessories_img, int(width_8_2))\n",
    "\n",
    "        # Calculate the midpoint\n",
    "        midpoint_x = int((point_2[0] + point_8[0]) / 2)\n",
    "        midpoint_y = int((point_2[1] + point_8[1]) / 2)\n",
    "        print(\"&&&&&&&& mid between 8 and 2 midpoint_x  and midpoint_y\", midpoint_x, midpoint_y)\n",
    "\n",
    "        \n",
    "        point_17 = next(sublist for sublist in filter_kpts if sublist[2] == 17)\n",
    "        \n",
    "        mid_17_bet_width_8_2 = np.sqrt((midpoint_x - point_17[0])**2 + (midpoint_y - point_17[1])**2)\n",
    "        print('width between mid and 17: ', mid_17_bet_width_8_2)\n",
    "\n",
    "        if mid_17_bet_width_8_2 <= 100:\n",
    "            percentage_to_subtract = 35\n",
    "            offset_y = int(percentage_to_subtract / 100 * resized_accessories_img.shape[1])\n",
    "            image = cvzone.overlayPNG(animal_image, resized_accessories_img, (point_8[0] , point_8[1] - offset_y))\n",
    "            \n",
    "        else:\n",
    "            midpoint_x_17 = int((midpoint_x + point_17[0]) / 2)\n",
    "            midpoint_y_17 = int((midpoint_y + point_17[1]) / 2)\n",
    "            print(\"^^^^^^^^^^^^^^^^ mid between mid and 7 \", midpoint_x_17, midpoint_y_17)\n",
    "            \n",
    "            ######## show point in specific location\n",
    "            percentage_to_subtract = 45\n",
    "            offset_y = int(percentage_to_subtract / 100 * resized_accessories_img.shape[1])\n",
    "    \n",
    "            \n",
    "            \n",
    "            image = cvzone.overlayPNG(animal_image, resized_accessories_img, (midpoint_x_17 - offset_y, midpoint_y_17 - offset_y))\n",
    "        return image        \n",
    "        # cv2.imwrite(\"resized_accessories_img_check.jpg\", image)\n",
    "        # cv2.imshow(\"resized_accessories_img\", image)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "            \n",
    "        \n",
    "        \n",
    "    else:\n",
    "        missing_points = [point for point in points_to_check if point not in [sublist[2] for sublist in filter_kpts]]\n",
    "        print(f\" ************The following points are missing: {missing_points}\")\n",
    "    ############################### cap working end ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06de8e9b-f959-4c49-8b81-78a46c0d6e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\closet\\tryon\\animal-tryon\\input\\dog1.jpg: 640x448 1 dog, 516.7ms\n",
      "Speed: 2.0ms preprocess, 516.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "results.boxes.xyxy.numpy() [[         89          80         587         926]]\n",
      "******** old filter_kpts:  [[432, 906, 0], [402, 794, 1], [391, 613, 2], [202, 895, 6], [224, 785, 7], [227, 606, 8], [423, 164, 14], [304, 147, 15], [343, 322, 16], [341, 378, 17], [450, 94, 18], [294, 73, 19]]\n",
      "point_8 and point_2 [227, 606, 8] [391, 613, 2]\n",
      "exits+++++++++++++++++\n",
      "&&&&&&&& mid between 8 and 2 midpoint_x  and midpoint_y 309 609\n",
      "width between mid and 17:  233.20591759215716\n",
      "^^^^^^^^^^^^^^^^ mid between mid and 7  325 493\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvzone\n",
    "from PIL import Image \n",
    "\n",
    "model_path = 'animal-tryon/best.pt'\n",
    "keywords_file = \"animal-tryon/keypoint_definitions.csv\"\n",
    "# animal_img = 'animal-tryon/input/HD-wallpaper-dog-ears-sitting-big.jpg'\n",
    "# animal_img = 'animal-tryon/images_data/frame_56.png'\n",
    "animal_img = 'animal-tryon/input/dog1.jpg'\n",
    "\n",
    "# accessories_img = 'animal-tryon/accessories/collar-edited.png'\n",
    "# result_png = 'png_result.png'\n",
    "accessories_img_path = \"animal-tryon/accessories/edited_images/12 I'm So Hungry/pet-light-red-cropped.png\"\n",
    "result_png = \"2. 12 I'm So Hungry(Product result).png\"\n",
    "\n",
    "ann_meta_data = pd.read_csv(keywords_file)\n",
    "COLORS = ann_meta_data[\"Hex colour\"].values.tolist()\n",
    "\n",
    "COLORS_RGB_MAP = []\n",
    "for color in COLORS:\n",
    "    R, G, B = int(color[:2], 16), int(color[2:4], 16), int(color[4:], 16)\n",
    "    COLORS_RGB_MAP.append({color: (R,G,B)})\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "BOX_IOU_THRESH = 0.55\n",
    "BOX_CONF_THRESH=0.30\n",
    "KPT_CONF_THRESH=0.68\n",
    "\n",
    "inc = 15\n",
    "\n",
    "\n",
    "\n",
    "animal_image = cv2.imread(animal_img)\n",
    "animal_image = cv2.cvtColor(animal_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "accessories_img = cv2.imread(accessories_img_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "\n",
    "results = model.predict(animal_img, conf=BOX_CONF_THRESH, iou=BOX_IOU_THRESH)[0].cpu()\n",
    "\n",
    "if not len(results.boxes.xyxy):\n",
    "    animal_image\n",
    "\n",
    "# Get the predicted boxes, conf scores and keypoints.\n",
    "pred_boxes = results.boxes.xyxy.numpy()\n",
    "pred_box_conf = results.boxes.conf.numpy()\n",
    "pred_kpts_xy = results.keypoints.xy.numpy()\n",
    "pred_kpts_conf = results.keypoints.conf.numpy()\n",
    "\n",
    "print('results.boxes.xyxy.numpy()', results.boxes.xyxy.numpy())\n",
    "\n",
    "\n",
    "\n",
    "# Draw predicted bounding boxes, conf scores and keypoints on image.\n",
    "for boxes, score, kpts, confs in zip(pred_boxes, pred_box_conf, pred_kpts_xy, pred_kpts_conf):\n",
    "    kpts_ids = np.where(confs > KPT_CONF_THRESH)[0]\n",
    "    filter_kpts = kpts[kpts_ids]\n",
    "    filter_kpts = np.concatenate([filter_kpts, np.expand_dims(kpts_ids, axis=-1)], axis=-1)\n",
    "    \n",
    "    # filter_kpts = filter_kpts.astype(\"int\").tolist()\n",
    "    filter_kpts = [[int(x) for x in inner_list] for inner_list in filter_kpts]\n",
    "    print('******** old filter_kpts: ', filter_kpts)\n",
    "    # animal_image = draw_landmarks(animal_image, filter_kpts)\n",
    "\n",
    "    animal_image = cv2.cvtColor(animal_image, cv2.COLOR_BGR2RGB)\n",
    "    # animal_image = draw_landmarks(animal_image, filter_kpts)\n",
    "    \n",
    "    img_result = wear_collar(accessories_img, animal_image, filter_kpts)\n",
    "    \n",
    "    # cv2.imshow(\"resized_accessories_img\", animal_image)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    # Check if the resulting image has valid dimensions\n",
    "    if img_result is not None and img_result.shape[0] > 0 and img_result.shape[1] > 0:\n",
    "        cv2.imwrite(result_png, img_result) \n",
    "        cv2.imshow(\"cap_wear_result\", img_result)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Error: Invalid dimensions for the resulting image.\")\n",
    "\n",
    "        # print(\"********************* Neither 14 nor 15 exists.\")\n",
    "    ################ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592417a-a7ae-4396-a6d5-fe2e28ad3ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551fc002-9240-443a-8608-8b8b09bb5050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238034f-ef5e-482d-91b5-a6913ac42797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
