{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a09a3990-3263-4d1b-9187-611feeccc917",
   "metadata": {},
   "source": [
    "# Work on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fc97a4e-0380-498d-b62e-950adf4de756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, landmarks):\n",
    "    radius = 5\n",
    "\n",
    "    # Check if image width is greater than 1000 px.\n",
    "    # To improve visualization.\n",
    "    if image.shape[1] > 1000:\n",
    "        radius = 8\n",
    "\n",
    "    for idx, kpt_data in enumerate(landmarks):\n",
    "        loc_x, loc_y = np.array(kpt_data[:2], dtype=int).tolist()\n",
    "        color_id = list(COLORS_RGB_MAP[int(kpt_data[-1])].values())[0]\n",
    "\n",
    "        cv2.circle(image,\n",
    "                   (loc_x, loc_y),\n",
    "                   radius,\n",
    "                   color=color_id[::-1],\n",
    "                   thickness=-1,\n",
    "                   lineType=cv2.LINE_AA)\n",
    "\n",
    "      # Draw keypoint number\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 0.5\n",
    "    font_thickness = 1\n",
    "    # text = str(int(kpt_data[-1]))\n",
    "    text = f\"{int(kpt_data[-1])}: ({loc_x}, {loc_y})\"\n",
    "    text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]\n",
    "    text_x = loc_x - text_size[0] // 2\n",
    "    text_y = loc_y - radius - 5\n",
    "    print('************* text:', text)\n",
    "    cv2.putText(image, text, (text_x, text_y), font, font_scale, color=(255, 255, 255), thickness=font_thickness)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ebea80c-56c1-47f4-840a-aedde29e0cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(img, new_width=None, new_height=None):\n",
    "    # Get the current height and width\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # If only width is specified\n",
    "    if new_width is not None and new_height is None:\n",
    "        # Calculate the aspect ratio and new height\n",
    "        aspect_ratio = width / height\n",
    "        new_height = int(new_width / aspect_ratio)\n",
    "\n",
    "    # If only height is specified\n",
    "    elif new_height is not None and new_width is None:\n",
    "        # Calculate the aspect ratio and new width\n",
    "        aspect_ratio = height / width\n",
    "        new_width = int(new_height / aspect_ratio)\n",
    "\n",
    "    # If both width and height are specified, ignore aspect ratio\n",
    "    elif new_width is not None and new_height is not None:\n",
    "        pass\n",
    "\n",
    "    # Resize the image\n",
    "    resized_img = cv2.resize(img, (new_width, new_height))\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "541aa735-f3c5-48d4-8b52-d2f67a7b9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### cap working ############################### \n",
    "def wear_cap(cap,animal_image,  filter_kpts):\n",
    "    \n",
    "\n",
    "    ################# Check two points (if 14 and 15 exist in the third item of each list)\n",
    "    \n",
    "    point_14_exists = any(14 == sublist[2] for sublist in filter_kpts)\n",
    "    point_15_exists = any(15 == sublist[2] for sublist in filter_kpts)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ################ check four points \n",
    "\n",
    "    # Points to check\n",
    "    points_to_check = [14, 15, 19, 18]\n",
    "    \n",
    "    # Check if all points exist in the third item of any list\n",
    "    all_points_exist = all(point in [sublist[2] for sublist in filter_kpts] for point in points_to_check)\n",
    "    print(f'----------****** four points exits ******----------{all_points_exist}', )\n",
    "    if all_points_exist:\n",
    "        print(\"************ All points exist.\")\n",
    "        \n",
    "\n",
    "        ## *********** check if 19 > 15 and 18 > 14 (condition to correct image flip )\n",
    "        # get value of 19 and 15\n",
    "        point_19 = next(sublist for sublist in filter_kpts if sublist[2] == 19)\n",
    "        point_15 = next(sublist for sublist in filter_kpts if sublist[2] == 15)\n",
    "\n",
    "        if point_19[1] > point_15[1]:\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "            # get value of 18 and 14\n",
    "            point_18 = next(sublist for sublist in filter_kpts if sublist[2] == 18)\n",
    "            point_14 = next(sublist for sublist in filter_kpts if sublist[2] == 14)\n",
    "\n",
    "            # Calculate the width between points 14 and 15\n",
    "            width_19_15 = np.sqrt((point_19[0] - point_15[0])**2 + (point_19[1] - point_15[1])**2)\n",
    "            \n",
    "            # Calculate the width between points 14 and 15\n",
    "            width_18_14 = np.sqrt((point_18[0] - point_14[0])**2 + (point_18[1] - point_14[1])**2)\n",
    "            \n",
    "            print('>>>>>>>>>>>>>>>> length of 18 and 14: ', width_18_14)\n",
    "            print('>>>>>>>>>>>>>>>> length of 19 and 15: ', width_19_15)\n",
    "            print('\\n19, 15, 18, 14 origranl', [point_19, point_15, point_18, point_14])\n",
    "    \n",
    "            point_19[1] = int(point_19[1] - 2 * width_19_15)\n",
    "            point_18[1] = int(point_18[1] - 2 * width_18_14)\n",
    "            \n",
    "            print('19, 15, 18, 14 decreamented\\n', [point_19, point_15, point_18, point_14])\n",
    "\n",
    "            filter_kpts[-1] = point_19 \n",
    "            filter_kpts[-2] = point_18\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        # cap = cv2.imread(accessories_img_path, cv2.IMREAD_UNCHANGED)\n",
    "        cap_h,cap_w =  cap.shape[:2]\n",
    "\n",
    "        print('******** new filter_kpts: ', filter_kpts)\n",
    "        \n",
    "        \n",
    "        head_coordinates = [item for item in filter_kpts if item[2] in points_to_check]\n",
    "        head_coordinates_position = sorted(head_coordinates, key=lambda x: x[2], reverse=True)\n",
    "        print('-------------------- head coordinates position with keypoint numbers: ', head_coordinates_position)\n",
    "        print('-------------------- length of head coordinates position: ', len(head_coordinates_position))\n",
    "        \n",
    "        head_coordinates_position = [[item[0], item[1] + inc] for item in head_coordinates_position]\n",
    "        print('-------------------- head coordinates position without keypoint numbers: ', head_coordinates_position)\n",
    "        \n",
    "        pts1=np.float32([[0,0],[cap_w,0],[0,cap_h],[cap_w,cap_h]])\n",
    "        pts2=np.float32(head_coordinates_position)\n",
    "        \n",
    "        h, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC,5.0)\n",
    "    \n",
    "        height, width, channels = animal_image.shape\n",
    "        im1Reg = cv2.warpPerspective(cap, h, (width, height))\n",
    "        animal_image = cv2.cvtColor(animal_image, cv2.COLOR_BGR2RGB) \n",
    "        animal_image_result = cvzone.overlayPNG(animal_image, im1Reg, (0, 0))\n",
    "        \n",
    "        # cv2.imshow(\"Original Image\", animal_image_result)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        return animal_image_result\n",
    "    \n",
    "    elif point_14_exists and point_15_exists:\n",
    "\n",
    "        \n",
    "        # get value of 14 and 15\n",
    "        point_14 = next(sublist for sublist in filter_kpts if sublist[2] == 14)\n",
    "        point_15 = next(sublist for sublist in filter_kpts if sublist[2] == 15)\n",
    "        \n",
    "        print(\"********************* Both 14 and 15 exist.\")\n",
    "        \n",
    "\n",
    "        \n",
    "        # Calculate the width between points 14 and 15\n",
    "        width_14_15 = np.sqrt((point_14[0] - point_15[0])**2 + (point_14[1] - point_15[1])**2)\n",
    "        resized_accessories_img  = resize_with_aspect_ratio(cap, int(width_14_15))\n",
    "\n",
    "        \n",
    "        print(f\"********************* The width between points 14 and 15 is: {width_14_15}\")\n",
    "        animal_image = cv2.cvtColor(animal_image, cv2.COLOR_RGB2BGR) \n",
    "\n",
    "        print('%%%%%%%%%%% shape of png', resized_accessories_img.shape)\n",
    "        \n",
    "\n",
    "        percentage_to_subtract = 38 \n",
    "        offset_y = int(percentage_to_subtract / 100 * resized_accessories_img.shape[1])\n",
    "        \n",
    "        animal_image_result = cvzone.overlayPNG(animal_image, resized_accessories_img, (point_15[0], point_15[1] - offset_y ))\n",
    "\n",
    "        \n",
    "        # cv2.imshow(\"Original Image\", animal_image_result)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        return animal_image_result\n",
    "    ################# Check two points code end\n",
    "    else:\n",
    "        missing_points = [point for point in points_to_check if point not in [sublist[2] for sublist in filter_kpts]]\n",
    "        print(f\" ************The following points are missing: {missing_points}\")\n",
    "############################### cap working end ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7371e5e4-6234-4ba3-b3c5-2daf22562e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 D:\\closet\\tryon\\animal-tryon\\input\\dog1.jpg: 640x448 1 dog, 361.8ms\n",
      "Speed: 3.0ms preprocess, 361.8ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 448)\n",
      "******** old filter_kpts:  [[432, 906, 0], [402, 794, 1], [391, 613, 2], [202, 895, 6], [224, 785, 7], [227, 606, 8], [423, 164, 14], [304, 147, 15], [343, 322, 16], [341, 378, 17], [450, 94, 18], [294, 73, 19]]\n",
      "----------****** four points exits ******----------True\n",
      "************ All points exist.\n",
      "******** new filter_kpts:  [[432, 906, 0], [402, 794, 1], [391, 613, 2], [202, 895, 6], [224, 785, 7], [227, 606, 8], [423, 164, 14], [304, 147, 15], [343, 322, 16], [341, 378, 17], [450, 94, 18], [294, 73, 19]]\n",
      "-------------------- head coordinates position with keypoint numbers:  [[294, 73, 19], [450, 94, 18], [304, 147, 15], [423, 164, 14]]\n",
      "-------------------- length of head coordinates position:  4\n",
      "-------------------- head coordinates position without keypoint numbers:  [[294, 88], [450, 109], [304, 162], [423, 179]]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvzone\n",
    "from PIL import Image \n",
    "\n",
    "model_path = 'animal-tryon/best.pt'\n",
    "keywords_file = \"animal-tryon/keypoint_definitions.csv\"\n",
    "animal_img = 'animal-tryon/input/dog1.jpg'\n",
    "# animal_img = 'animal-tryon/images_data/frame_56.png'\n",
    "\n",
    "accessories_img = 'animal-tryon/accessories/edited_images/07 Sky & Cloud/เหลือง3.png'\n",
    "result_png = '4. Sky & Cloud(Product result).png'\n",
    "\n",
    "\n",
    "ann_meta_data = pd.read_csv(keywords_file)\n",
    "COLORS = ann_meta_data[\"Hex colour\"].values.tolist()\n",
    "\n",
    "COLORS_RGB_MAP = []\n",
    "for color in COLORS:\n",
    "    R, G, B = int(color[:2], 16), int(color[2:4], 16), int(color[4:], 16)\n",
    "    COLORS_RGB_MAP.append({color: (R,G,B)})\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "BOX_IOU_THRESH = 0.55\n",
    "BOX_CONF_THRESH=0.30\n",
    "KPT_CONF_THRESH=0.68\n",
    "\n",
    "inc = 15\n",
    "\n",
    "\n",
    "\n",
    "animal_image = cv2.imread(animal_img)\n",
    "animal_image = cv2.cvtColor(animal_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "cap = cv2.imread(accessories_img, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "results = model.predict(animal_img, conf=BOX_CONF_THRESH, iou=BOX_IOU_THRESH)[0].cpu()\n",
    "\n",
    "if not len(results.boxes.xyxy):\n",
    "    animal_image\n",
    "\n",
    "# Get the predicted boxes, conf scores and keypoints.\n",
    "pred_boxes = results.boxes.xyxy.numpy()\n",
    "pred_box_conf = results.boxes.conf.numpy()\n",
    "pred_kpts_xy = results.keypoints.xy.numpy()\n",
    "pred_kpts_conf = results.keypoints.conf.numpy()\n",
    "\n",
    "# Draw predicted bounding boxes, conf scores and keypoints on image.\n",
    "for boxes, score, kpts, confs in zip(pred_boxes, pred_box_conf, pred_kpts_xy, pred_kpts_conf):\n",
    "    kpts_ids = np.where(confs > KPT_CONF_THRESH)[0]\n",
    "    filter_kpts = kpts[kpts_ids]\n",
    "    filter_kpts = np.concatenate([filter_kpts, np.expand_dims(kpts_ids, axis=-1)], axis=-1)\n",
    "    \n",
    "    # filter_kpts = filter_kpts.astype(\"int\").tolist()\n",
    "    filter_kpts = [[int(x) for x in inner_list] for inner_list in filter_kpts]\n",
    "    print('******** old filter_kpts: ', filter_kpts)\n",
    "    # animal_image = draw_landmarks(animal_image, filter_kpts)\n",
    "    cap_wear_result = wear_cap(cap, animal_image, filter_kpts)\n",
    "    # Check if the resulting image has valid dimensions\n",
    "    if cap_wear_result is not None and cap_wear_result.shape[0] > 0 and cap_wear_result.shape[1] > 0:\n",
    "        cv2.imwrite(result_png, cap_wear_result) \n",
    "        cv2.imshow(\"cap_wear_result\", cap_wear_result)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"Error: Invalid dimensions for the resulting image.\")\n",
    "\n",
    "        # print(\"********************* Neither 14 nor 15 exists.\")\n",
    "    ################ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436bdddd-b039-4113-858b-f29dfa58deed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "738ea668-9156-44ca-b7b8-a85f3070a7cc",
   "metadata": {},
   "source": [
    "# Working on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19003e-7b46-40e6-96ef-571dcfff37bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvzone\n",
    "from PIL import Image \n",
    "\n",
    "model_path = 'animal-tryon/best.pt'\n",
    "keywords_file = \"animal-tryon/keypoint_definitions.csv\"\n",
    "\n",
    "accessories_img = 'animal-tryon/accessories/hat1.png'\n",
    "result_png = 'png_result.png'\n",
    "\n",
    "ann_meta_data = pd.read_csv(keywords_file)\n",
    "COLORS = ann_meta_data[\"Hex colour\"].values.tolist()\n",
    "\n",
    "COLORS_RGB_MAP = []\n",
    "for color in COLORS:\n",
    "    R, G, B = int(color[:2], 16), int(color[2:4], 16), int(color[4:], 16)\n",
    "    COLORS_RGB_MAP.append({color: (R,G,B)})\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "BOX_IOU_THRESH = 0.55\n",
    "BOX_CONF_THRESH=0.30\n",
    "KPT_CONF_THRESH=0.68\n",
    "\n",
    "inc = 15\n",
    "\n",
    "def wear_cap(accessories_img_path,animal_image,  filter_kpts):\n",
    "    ############################### cap working ############################### \n",
    "\n",
    "    ################# Check two points (if 14 and 15 exist in the third item of each list)\n",
    "    \n",
    "    point_14_exists = any(14 == sublist[2] for sublist in filter_kpts)\n",
    "    point_15_exists = any(15 == sublist[2] for sublist in filter_kpts)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    ################ check four points \n",
    "\n",
    "    # Points to check\n",
    "    points_to_check = [14, 15, 19, 18]\n",
    "    \n",
    "    # Check if all points exist in the third item of any list\n",
    "    all_points_exist = all(point in [sublist[2] for sublist in filter_kpts] for point in points_to_check)\n",
    "    print(f'----------****** four points exits ******----------{all_points_exist}', )\n",
    "    if all_points_exist:\n",
    "        print(\"************ All points exist.\")\n",
    "        \n",
    "\n",
    "        ## *********** check if 19 > 15 and 18 > 14 (condition to correct image flip )\n",
    "        # get value of 19 and 15\n",
    "        point_19 = next(sublist for sublist in filter_kpts if sublist[2] == 19)\n",
    "        point_15 = next(sublist for sublist in filter_kpts if sublist[2] == 15)\n",
    "\n",
    "        if point_19[1] > point_15[1]:\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "            # get value of 18 and 14\n",
    "            point_18 = next(sublist for sublist in filter_kpts if sublist[2] == 18)\n",
    "            point_14 = next(sublist for sublist in filter_kpts if sublist[2] == 14)\n",
    "\n",
    "            # Calculate the width between points 14 and 15\n",
    "            width_19_15 = np.sqrt((point_19[0] - point_15[0])**2 + (point_19[1] - point_15[1])**2)\n",
    "            \n",
    "            # Calculate the width between points 14 and 15\n",
    "            width_18_14 = np.sqrt((point_18[0] - point_14[0])**2 + (point_18[1] - point_14[1])**2)\n",
    "            \n",
    "            print('>>>>>>>>>>>>>>>> length of 18 and 14: ', width_18_14)\n",
    "            print('>>>>>>>>>>>>>>>> length of 19 and 15: ', width_19_15)\n",
    "            print('\\n19, 15, 18, 14 origranl', [point_19, point_15, point_18, point_14])\n",
    "    \n",
    "            point_19[1] = int(point_19[1] - 2 * width_19_15)\n",
    "            point_18[1] = int(point_18[1] - 2 * width_18_14)\n",
    "            \n",
    "            print('19, 15, 18, 14 decreamented\\n', [point_19, point_15, point_18, point_14])\n",
    "\n",
    "            filter_kpts[-1] = point_19 \n",
    "            filter_kpts[-2] = point_18\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        cap = cv2.imread(accessories_img_path, cv2.IMREAD_UNCHANGED)\n",
    "        cap_h,cap_w =  cap.shape[:2]\n",
    "\n",
    "        print('******** new filter_kpts: ', filter_kpts)\n",
    "        \n",
    "        \n",
    "        head_coordinates = [item for item in filter_kpts if item[2] in points_to_check]\n",
    "        head_coordinates_position = sorted(head_coordinates, key=lambda x: x[2], reverse=True)\n",
    "        print('-------------------- head coordinates position with keypoint numbers: ', head_coordinates_position)\n",
    "        print('-------------------- length of head coordinates position: ', len(head_coordinates_position))\n",
    "        \n",
    "        head_coordinates_position = [[item[0], item[1] + inc] for item in head_coordinates_position]\n",
    "        print('-------------------- head coordinates position without keypoint numbers: ', head_coordinates_position)\n",
    "        \n",
    "        pts1=np.float32([[0,0],[cap_w,0],[0,cap_h],[cap_w,cap_h]])\n",
    "        pts2=np.float32(head_coordinates_position)\n",
    "        \n",
    "        h, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC,5.0)\n",
    "    \n",
    "        height, width, channels = animal_image.shape\n",
    "        im1Reg = cv2.warpPerspective(cap, h, (width, height))\n",
    "        animal_image = cv2.cvtColor(animal_image, cv2.COLOR_BGR2RGB) \n",
    "        animal_image_result = cvzone.overlayPNG(animal_image, im1Reg, (0, 0))\n",
    "        \n",
    "        # cv2.imshow(\"Original Image\", animal_image_result)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        return animal_image_result\n",
    "    \n",
    "    elif point_14_exists and point_15_exists:\n",
    "\n",
    "        \n",
    "        # get value of 14 and 15\n",
    "        point_14 = next(sublist for sublist in filter_kpts if sublist[2] == 14)\n",
    "        point_15 = next(sublist for sublist in filter_kpts if sublist[2] == 15)\n",
    "        \n",
    "        print(\"********************* Both 14 and 15 exist.\")\n",
    "        \n",
    "\n",
    "        \n",
    "        # Calculate the width between points 14 and 15\n",
    "        width_14_15 = np.sqrt((point_14[0] - point_15[0])**2 + (point_14[1] - point_15[1])**2)\n",
    "        resized_accessories_img  = resize_with_aspect_ratio(accessories_img_path, int(width_14_15))\n",
    "\n",
    "        \n",
    "        print(f\"********************* The width between points 14 and 15 is: {width_14_15}\")\n",
    "        animal_image = cv2.cvtColor(animal_image, cv2.COLOR_RGB2BGR) \n",
    "\n",
    "        print('%%%%%%%%%%% shape of png', resized_accessories_img.shape)\n",
    "        \n",
    "\n",
    "        percentage_to_subtract = 38 \n",
    "        offset_y = int(percentage_to_subtract / 100 * resized_accessories_img.shape[1])\n",
    "        \n",
    "        animal_image_result = cvzone.overlayPNG(animal_image, resized_accessories_img, (point_15[0], point_15[1] - offset_y ))\n",
    "\n",
    "        \n",
    "        # cv2.imshow(\"Original Image\", animal_image_result)\n",
    "        # cv2.waitKey(0)\n",
    "        # cv2.destroyAllWindows()\n",
    "\n",
    "        return animal_image_result\n",
    "    ################# Check two points code end\n",
    "    else:\n",
    "        missing_points = [point for point in points_to_check if point not in [sublist[2] for sublist in filter_kpts]]\n",
    "        print(f\" ************The following points are missing: {missing_points}\")\n",
    "    ############################### cap working end ###############################\n",
    "\n",
    "\n",
    "# Open the video file\n",
    "video_path = 'animal-tryon/input/dog_video2.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# # Get the frames per second (fps) of the video\n",
    "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# # We need to set resolutions. \n",
    "# # so, convert them from float to integer. \n",
    "# frame_width = int(cap.get(3)) \n",
    "# frame_height = int(cap.get(4)) \n",
    "   \n",
    "# size = (frame_width, frame_height) \n",
    "   \n",
    "# Below VideoWriter object will create \n",
    "# a frame of above defined The output  \n",
    "# is stored in 'filename.avi' file. \n",
    "# result = cv2.VideoWriter('filename.avi',  \n",
    "#                          cv2.VideoWriter_fourcc(*'MJPG'), \n",
    "#                          10, size) \n",
    "\n",
    "\n",
    "# get FPS of input video \n",
    "fps = cap.get(cv2.CAP_PROP_FPS) \n",
    "\n",
    "# define output video and it's FPS \n",
    "output_file = 'output2.mp4'\n",
    "output_fps = fps * 2\n",
    "  \n",
    "# define VideoWriter object \n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "out = cv2.VideoWriter(output_file, fourcc, output_fps, \n",
    "                      (int(cap.get(3)), int(cap.get(4)))) \n",
    "\n",
    "counter  = 1\n",
    "while cap.isOpened():\n",
    "    ret, animal_image = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    # animal_image = cv2.cvtColor(animal_image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # results = model.predict(animal_image, conf=BOX_CONF_THRESH, ioQu=BOX_IOU_THRESH)[0].cpu()\n",
    "    results = model.predict(animal_image, conf=BOX_CONF_THRESH, iou=BOX_IOU_THRESH)[0].cpu()\n",
    "\n",
    "    if not len(results.boxes.xyxy):\n",
    "        animal_image\n",
    "    \n",
    "    # Get the predicted boxes, conf scores and keypoints.\n",
    "    pred_boxes = results.boxes.xyxy.numpy()\n",
    "    pred_box_conf = results.boxes.conf.numpy()\n",
    "    pred_kpts_xy = results.keypoints.xy.numpy()\n",
    "    pred_kpts_conf = results.keypoints.conf.numpy()\n",
    "    \n",
    "    # Draw predicted bounding boxes, conf scores and keypoints on image.\n",
    "    for boxes, score, kpts, confs in zip(pred_boxes, pred_box_conf, pred_kpts_xy, pred_kpts_conf):\n",
    "        kpts_ids = np.where(confs > KPT_CONF_THRESH)[0]\n",
    "        filter_kpts = kpts[kpts_ids]\n",
    "        filter_kpts = np.concatenate([filter_kpts, np.expand_dims(kpts_ids, axis=-1)], axis=-1)\n",
    "        \n",
    "        # filter_kpts = filter_kpts.astype(\"int\").tolist()\n",
    "        filter_kpts = [[int(x) for x in inner_list] for inner_list in filter_kpts]\n",
    "        print('******** filter_kpts: ', filter_kpts)\n",
    "\n",
    "    animal_image = cv2.cvtColor(animal_image, cv2.COLOR_BGR2RGB)\n",
    "    # animal_image = draw_landmarks(animal_image, filter_kpts)\n",
    "    cap_wear_result = wear_cap(accessories_img, animal_image, filter_kpts)\n",
    "    \n",
    "    # Write the frame to the output video\n",
    "    out.write(cap_wear_result) \n",
    "    \n",
    "    # Show the frame\n",
    "    # cv2.imshow(\"Original Image\", cap_wear_result)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Wait to achieve the desired frame rate (30fps)\n",
    "    cv2.waitKey(int(1000 / fps))\n",
    "    print(f'*********************** {counter} frames done ***********************')\n",
    "    counter+=1\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
